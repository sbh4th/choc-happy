abline( m5.0 )
tweetRcode:::tweetRcodeAddin()
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# fit model
# m5.0 <- lm(Divorce ~ WaffleHouses, data=d)
flist <- alist(Divorce ~ dnorm( mu , sigma ) , mu <- a + bA * WaffleHouses, a ~ dnorm(10,10), bA <- dnorm(0,1), sigma ~ dunif(0,10))
m5.0 <- map(flist, data=d)
plot( Divorce ~ WaffleHouses , data=d , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate" )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0 )
tweetRcode:::tweetRcodeAddin()
## R code 7.1
library(rethinking)
data(rugged)
d <- rugged
# make log version of outcome
d$log_gdp <- log( d$rgdppc_2000 )
# extract countries with GDP data
dd <- d[ complete.cases(d$rgdppc_2000) , ]
# split countries into Africa and not-Africa
d.A1 <- dd[ dd$cont_africa==1 , ] # Africa
d.A0 <- dd[ dd$cont_africa==0 , ] # not Africa
## R code 7.9
m7.5b <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bAR*rugged*cont_africa + bA*cont_africa,
a ~ dnorm( 8 , 100 ) ,
bA ~ dnorm( 0 , 1 ) ,
bR ~ dnorm( 0 , 1 ) ,
bAR ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data=dd )
## R code 7.10
rugged.seq <- seq(from=-1,to=8,by=0.25)
mu.Africa <- link( m7.5 , data=data.frame(cont_africa=1,rugged=rugged.seq) )
mu.Africa.mean <- apply( mu.Africa , 2 , mean )
mu.Africa.PI <- apply( mu.Africa , 2 , PI , prob=0.97 )
mu.NotAfrica <- link( m7.5 , data=data.frame(cont_africa=0,rugged=rugged.seq) )
mu.NotAfrica.mean <- apply( mu.NotAfrica , 2 , mean )
mu.NotAfrica.PI <- apply( mu.NotAfrica , 2 , PI , prob=0.97 )
## R code 7.7
m7.5 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + gamma*rugged + bA*cont_africa ,
gamma <- bR + bAR*cont_africa ,
a ~ dnorm( 8 , 100 ) ,
bA ~ dnorm( 0 , 1 ) ,
bR ~ dnorm( 0 , 1 ) ,
bAR ~ dnorm( 0 , 1 ) ,
sigma ~ dunif( 0 , 10 )
) ,
data=dd )
## R code 7.10
rugged.seq <- seq(from=-1,to=8,by=0.25)
mu.Africa <- link( m7.5 , data=data.frame(cont_africa=1,rugged=rugged.seq) )
mu.Africa.mean <- apply( mu.Africa , 2 , mean )
mu.Africa.PI <- apply( mu.Africa , 2 , PI , prob=0.97 )
mu.NotAfrica <- link( m7.5 , data=data.frame(cont_africa=0,rugged=rugged.seq) )
mu.NotAfrica.mean <- apply( mu.NotAfrica , 2 , mean )
mu.NotAfrica.PI <- apply( mu.NotAfrica , 2 , PI , prob=0.97 )
d.A1 <- dd[dd$cont_africa==1,]
plot( log(rgdppc_2000) ~ rugged , data=d.A1 ,
col=rangi2 , ylab="log GDP year 2000" ,
xlab="Terrain Ruggedness Index" )
mtext( "African nations" , 3 )
lines( rugged.seq , mu.Africa.mean , col=rangi2 )
shade( mu.Africa.PI , rugged.seq , col=col.alpha(rangi2,0.3) )
# plot non-African nations with regression
d.A0 <- dd[dd$cont_africa==0,]
plot( log(rgdppc_2000) ~ rugged , data=d.A0 ,
col="black" , ylab="log GDP year 2000" ,
xlab="Terrain Ruggedness Index" )
mtext( "Non-African nations" , 3 )
lines( rugged.seq , mu.NotAfrica.mean )
shade( mu.NotAfrica.PI , rugged.seq )
precis(m7.5)
post <- extract.samples( m7.5 )
gamma.Africa <- post$bR + post$bAR*1
gamma.notAfrica <- post$bR + post$bAR*0
mean( gamma.Africa)
mean( gamma.notAfrica )
dens( gamma.Africa , xlim=c(-0.5,0.6) , ylim=c(0,5.5) ,
xlab="gamma" , col=rangi2 )
dens( gamma.notAfrica , add=TRUE )
diff <- gamma.Africa - gamma.notAfrica
sum( diff < 0 ) / length( diff )
dens(diff)
??apply
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
# fit model
# m5.0 <- lm(Divorce ~ WaffleHouses, data=d)
flist <- alist(Divorce ~ dnorm( mu , sigma ) , mu <- a + bA * WaffleHouses, a ~ dnorm(10,10), bA <- dnorm(0,1), sigma ~ dunif(0,10))
m5.0 <- map(flist, data=d)
plot( Divorce ~ WaffleHouses , data=d , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate" )
identify( x=d$WaffleHouses , y=d$Divorce , labels=d$Loc , cex=0.8 )
View(d)
d.ga <- subset(WaffleDivorce,Location!="Georgia")
View(d.ga)
flist <- alist(Divorce ~ dnorm( mu , sigma ) , mu <- a + bA * WaffleHouses, a ~ dnorm(10,10), bA <- dnorm(0,1), sigma ~ dunif(0,10))
m5.0 <- map(flist, data=d.ga)
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate" )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0 )
precis( m5.0 )
m5.0 <- map(flist, data=d)
m5.0ga <- mat(flist, data=d.ga)
m5.0ga <- map(flist, data=d.ga)
precis( m5.0, m5.0ga)
precis( m5.0)
precis( m5.0ga)
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0ga )
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
d.ga <- subset(WaffleDivorce,Location!="Georgia")
# fit model
# m5.0 <- lm(Divorce ~ WaffleHouses, data=d)
flist <- alist(Divorce ~ dnorm( mu , sigma ) , mu <- a + bA * WaffleHouses, a ~ dnorm(10,10), bA <- dnorm(0,1), sigma ~ dunif(0,10))
m5.0 <- map(flist, data=d)
m5.0ga <- map(flist, data=d.ga)
par(mfrow=c(1,2)) # 1 row, 2 columns
plot( Divorce ~ WaffleHouses , data=d , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0 )
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0ga )
coeftab(m5.0,m5.0ga)
coefplot(m5.0,m5.0ga)
coeftab(m5.0,m5.0ga, se=T, nobs=T)
precis( m5.0 )
precis( m5.0ga )
m5.0 <- map(flist, data=d)
wh.seq <- seq( from=0 , to=d$WaffleHouses, length.out=30 )
mu <- link( m5.0 , data=data.frame(WaffleHouses=wh.seq) )
mu.PI <- apply( mu , 2 , PI )
m5.0 <- map(flist, data=d)
wh.seq <- seq( from=0 , to=400, length.out=30 )
mu <- link( m5.0 , data=data.frame(WaffleHouses=wh.seq) )
mu.PI <- apply( mu , 2 , PI )
m5.0ga <- map(flist, data=d.ga)
muga <- link( m5.0ga , data=data.frame(WaffleHouses=wh.seq) )
muga.PI <- apply( muga , 2 , PI )
par(mfrow=c(1,2)) # 1 row, 2 columns
plot( Divorce ~ WaffleHouses , data=d , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0 )
shade( mu.PI , wh.seq )
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0ga )
shade( muga.PI , wh.seq )
# m5.0 <- lm(Divorce ~ WaffleHouses, data=d)
flist <- alist(Divorce ~ dnorm( mu , sigma ) , mu <- a + bA * WaffleHouses, a ~ dnorm(10,10), bA <- dnorm(0,100), sigma ~ dunif(0,10))
m5.0 <- map(flist, data=d)
wh.seq <- seq( from=0 , to=400, length.out=30 )
mu <- link( m5.0 , data=data.frame(WaffleHouses=wh.seq) )
mu.PI <- apply( mu , 2 , PI )
m5.0ga <- map(flist, data=d.ga)
muga <- link( m5.0ga , data=data.frame(WaffleHouses=wh.seq) )
muga.PI <- apply( muga , 2 , PI )
par(mfrow=c(1,2)) # 1 row, 2 columns
plot( Divorce ~ WaffleHouses , data=d , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0 )
shade( mu.PI , wh.seq )
plot( Divorce ~ WaffleHouses , data=d.ga , col=rangi2, xlab="Waffle Houses per million" , ylab="Divorce Rate",xlim=range(d$WaffleHouses) , ylim=range(d$Divorce) )
with(d[1:9,], text(Divorce ~ WaffleHouses, labels = Loc, pos = 4))
abline( m5.0ga )
shade( muga.PI , wh.seq )
precis( m5.0 )
precis( m5.0ga )
lm(Divorce ~ WaffleHouses, data=d)
lm(Divorce ~ WaffleHouses, data=d.ga)
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
## R code 8.3
m8.1 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,10)
) ,
data=dd )
precis(m8.1)
## R code 8.4
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
str(dd.trim)
## R code 8.5
m8.1stan <- map2stan(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim )
install.packages(c("backports", "bayesm", "bayesplot", "Boom", "BoomSpikeSlab", "brms", "bsts", "car", "clusterPower", "coin", "colourpicker", "commonmark", "crayon", "data.table", "desc", "devtools", "doParallel", "episensr", "foreach", "Formula", "git2r", "gridExtra", "htmlwidgets", "iterators", "knitr", "ks", "Lahman", "lazyeval", "lme4", "mapproj", "maps", "MASS", "mclust", "MCMCpack", "metafor", "msm", "multcomp", "NLP", "pbapply", "PKI", "plotly", "PracTools", "pubmed.mineR", "purrr", "quantreg", "RcppArmadillo", "RcppEigen", "RCurl", "reshape", "reshape2", "rgenoud", "rgl", "robumeta", "robustbase", "rprojroot", "rsconnect", "rstan", "rstanarm", "rstantools", "sandwich", "scales", "shinyjs", "shinystan", "slam", "sp", "spatstat", "spatstat.utils", "StanHeaders", "statmod", "statnet.common", "survey", "threejs", "tibble", "tidyr", "tis", "tm", "triangle", "VGAM", "withr", "XML", "xts", "Zelig"))
install.packages(c("backports", "bayesm", "bayesplot", "Boom", "BoomSpikeSlab", "brms", "bsts", "car", "clusterPower", "coin", "colourpicker", "commonmark", "crayon", "data.table", "desc", "devtools", "doParallel", "episensr", "foreach", "Formula", "git2r", "gridExtra", "htmlwidgets", "iterators", "knitr", "ks", "Lahman", "lazyeval", "lme4", "mapproj", "maps", "MASS", "mclust", "MCMCpack", "metafor", "msm", "multcomp", "NLP", "pbapply", "PKI", "plotly", "PracTools", "pubmed.mineR", "purrr", "quantreg", "RcppArmadillo", "RcppEigen", "RCurl", "reshape", "reshape2", "rgenoud", "rgl", "robumeta", "robustbase", "rprojroot", "rsconnect", "rstan", "rstanarm", "rstantools", "sandwich", "scales", "shinyjs", "shinystan", "slam", "sp", "spatstat", "spatstat.utils", "StanHeaders", "statmod", "statnet.common", "survey", "threejs", "tibble", "tidyr", "tis", "tm", "triangle", "VGAM", "withr", "XML", "xts", "Zelig"))
install.packages(c("backports", "bayesm", "bayesplot", "Boom", "BoomSpikeSlab", "brms", "bsts", "car", "clusterPower", "coin", "colourpicker", "commonmark", "crayon", "data.table", "desc", "devtools", "doParallel", "episensr", "foreach", "Formula", "git2r", "gridExtra", "htmlwidgets", "iterators", "knitr", "ks", "Lahman", "lazyeval", "lme4", "mapproj", "maps", "MASS", "mclust", "MCMCpack", "metafor", "msm", "multcomp", "NLP", "pbapply", "PKI", "plotly", "PracTools", "pubmed.mineR", "purrr", "quantreg", "RcppArmadillo", "RcppEigen", "RCurl", "reshape", "reshape2", "rgenoud", "rgl", "robumeta", "robustbase", "rprojroot", "rsconnect", "rstan", "rstanarm", "rstantools", "sandwich", "scales", "shinyjs", "shinystan", "slam", "sp", "spatstat", "spatstat.utils", "StanHeaders", "statmod", "statnet.common", "survey", "threejs", "tibble", "tidyr", "tis", "tm", "triangle", "VGAM", "withr", "XML", "xts", "Zelig"))
install.packages(c("backports", "bayesm", "bayesplot", "Boom", "BoomSpikeSlab", "brms", "bsts", "car", "clusterPower", "coin", "colourpicker", "commonmark", "crayon", "data.table", "desc", "devtools", "doParallel", "episensr", "foreach", "Formula", "git2r", "gridExtra", "htmlwidgets", "iterators", "knitr", "ks", "Lahman", "lazyeval", "lme4", "mapproj", "maps", "MASS", "mclust", "MCMCpack", "metafor", "msm", "multcomp", "NLP", "pbapply", "PKI", "plotly", "PracTools", "pubmed.mineR", "purrr", "quantreg", "RcppArmadillo", "RcppEigen", "RCurl", "reshape", "reshape2", "rgenoud", "rgl", "robumeta", "robustbase", "rprojroot", "rsconnect", "rstan", "rstanarm", "rstantools", "sandwich", "scales", "shinyjs", "shinystan", "slam", "sp", "spatstat", "spatstat.utils", "StanHeaders", "statmod", "statnet.common", "survey", "threejs", "tibble", "tidyr", "tis", "tm", "triangle", "VGAM", "withr", "XML", "xts", "Zelig"))
## R code 8.2
library(rethinking)
data(rugged)
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[ complete.cases(d$rgdppc_2000) , ]
## R code 8.3
m8.1 <- map(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dunif(0,10)
) ,
data=dd )
precis(m8.1)
## R code 8.4
dd.trim <- dd[ , c("log_gdp","rugged","cont_africa") ]
str(dd.trim)
## R code 8.5
m8.1stan <- map2stan(
alist(
log_gdp ~ dnorm( mu , sigma ) ,
mu <- a + bR*rugged + bA*cont_africa + bAR*rugged*cont_africa ,
a ~ dnorm(0,100),
bR ~ dnorm(0,10),
bA ~ dnorm(0,10),
bAR ~ dnorm(0,10),
sigma ~ dcauchy(0,2)
) ,
data=dd.trim )
y <- c(-1,1)
m8.2 <- map2stan(
alist(
y ~ dnorm( mu , sigma ) ,
mu <- alpha
) ,
data=list(y=y) , start=list(alpha=0,sigma=1) ,
chains=2 , iter=4000 , warmup=1000 )
retrodesign <- function(A, s, alpha=.05, df=Inf, n.sims=10000){
z <- qt(1-alpha/2, df)
p.hi <- 1 - pt(z-A/s, df)
p.lo <- pt(-z-A/s, df)
power <- p.hi + p.lo
typeS <- p.lo/power
estimate <- A + s*rt(n.sims,df)
significant <- abs(estimate) > s*z
exaggeration <- mean(abs(estimate)[significant])/A
return(list(power=power, typeS=typeS, exaggeration=exaggeration))
}
retrodesign(.02, .038)
d <- dbinom(1,.5)
??dbinom
d <- dbinom(1,100,.3)
library(rethinking)
# define grid
p_grid <- seq( from=0 , to=1 , length.out=10 )
# define prior
prior <- rep( 1 , 10 )
# compute likelihood at each value in grid
likelihood <- dbinom( 5 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "10 points" )
# define grid
p_grid <- seq( from=0 , to=1 , length.out=10 )
# define prior
prior <- rep( 1 , 10 )
# compute likelihood at each value in grid
likelihood <- dbinom( 8 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "10 points" )
# define grid
p_grid <- seq( from=0 , to=1 , length.out=10 )
# define prior
prior <- rep( 1 , 10 )
# compute likelihood at each value in grid
likelihood <- dbinom( 5 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "10 points" )
# define grid
p_grid <- seq( from=0 , to=1 , length.out=100 )
# define prior
prior <- rep( 1 , 100 )
# compute likelihood at each value in grid
likelihood <- dbinom( 5 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "100 points" )
# define grid
p_grid <- seq( from=0 , to=1 , length.out=1000 )
# define prior
prior <- rep( 1 , 1000 )
# compute likelihood at each value in grid
likelihood <- dbinom( 5 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "100 points" )
dbinom(8,10,p=0.5)
dbinom(80,100,p=0.5)
dbinom(5,10,p=0.5)
dbinom(50,100,p=0.5)
dbinom(49,100,p=0.5)
# define grid
p_grid <- seq( from=0 , to=1 , length.out=10)
# define prior
prior <- rep( 1 , 10 )
# compute likelihood at each value in grid
likelihood <- dbinom( 5 , size=10 , prob=p_grid )
# compute product of likelihood and prior
unstd.posterior <- likelihood * prior
# standardize the posterior, so it sums to 1
posterior <- unstd.posterior / sum(unstd.posterior)
## R code 2.4
plot( p_grid , posterior , type="b" ,
xlab="probability of heads" , ylab="posterior probability" )
mtext( "10 points" )
log(1.89)*(sqrt(3)/3.14)
ln(1.89)*(sqrt(3)/3.14)
(log(21.03) - log(0.17)) / (2*1.96)
1.229058^2
((log(21.03) - log(0.17)) / (2*1.96))*((log(21.03) - log(0.17)) / (2*1.96))
((log(21.03) - log(0.17)) / (2*1.96))*((log(21.03) - log(0.17)) / (2*1.96)) * (sqrt(3)/3.14)
sqrt(((log(21.03) - log(0.17)) / (2*1.96)))
sqrt(((log(21.03) - log(0.17)) / (2*1.96))) * (sqrt(3)/3.14)
shiny::runApp('Dropbox/BlackWhiteGap/shinyapp main')
curve(dbeta(x, 5, 5))
curve(dbeta(x, 10, 5))
curve(dbeta(x, 10, 10))
curve(dbeta(x, 100, 100))
effectSizeRange <- seq(-0.5, 2, length=100)
plot(x=effectSizeRange, y=dnorm(effectSizeRange, mean=0.5, sd=0.2), type="l", ylab="Plausibility",
xlab="Effect size")
n1 <- 100 # sample size first group
B <- 1000 # number of Monte Carlo simulations (e.g., 5000)
n2 <- n1
ps <- c() # this vector stores the B p-values
for (i in 1:B) {
x <- rnorm(n1, mean=0, sd=1)
# in each Monte Carlo run: choose another true ES from the prior distribution
y <- rnorm(n2, mean=rnorm(1, mean=0.5, sd=0.2), sd=1)
t1 <- t.test(x, y)
ps <- c(ps, t1$p.value)
}
prop.table(table(ps < .05))
hist(ps[ps<.05])
n1 <- 1000 # sample size first group
B <- 1000 # number of Monte Carlo simulations (e.g., 5000)
n2 <- n1
ps <- c() # this vector stores the B p-values
for (i in 1:B) {
x <- rnorm(n1, mean=0, sd=1)
# in each Monte Carlo run: choose another true ES from the prior distribution
y <- rnorm(n2, mean=rnorm(1, mean=0.5, sd=0.2), sd=1)
t1 <- t.test(x, y)
ps <- c(ps, t1$p.value)
}
# compute power (= number of studies that have a p-value < .05)
prop.table(table(ps < .05))
# plot p-curve in significant range
hist(ps[ps<.05])
n1 <- 70 # sample size first group
B <- 1000 # number of Monte Carlo simulations (e.g., 5000)
n2 <- n1
ps <- c() # this vector stores the B p-values
for (i in 1:B) {
x <- rnorm(n1, mean=0, sd=1)
# in each Monte Carlo run: choose another true ES from the prior distribution
y <- rnorm(n2, mean=rnorm(1, mean=0.5, sd=0.2), sd=1)
t1 <- t.test(x, y)
ps <- c(ps, t1$p.value)
}
# compute power (= number of studies that have a p-value < .05)
prop.table(table(ps < .05))
# plot p-curve in significant range
hist(ps[ps<.05])
dpois??
??dpois
dbinom(7,24,x)
dbinom(x,7,24)
dbinom(7,24,p=0.5)
install.packages("ggThemeAssist")
library("ggThemeAssist", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library(RCurl)
library(rAltmetric)
library(dplyr)
# http://www.fredtrotter.com/2014/11/14/hacking-on-the-pubmed-api/
baseurl <- "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=1000&term="
# Advanced search query details, http://www.ncbi.nlm.nih.gov/pubmed/advanced
advq <- '("Epidemiology"[Journal] AND ("2012/01/01"[PDAT] : "2015/12/31"[PDAT])'
advq_encoded <- URLencode(advq)
q <- paste0(baseurl,advq_encoded)
res <- getURLContent(q)
res_parsed <- jsonlite::fromJSON(res)
ids <- res_parsed$esearchresult$idlist
ids2 <- paste("pmid/", ids, sep = "")
ids3 <- paste("pmid/", ids, sep = "")
# Query Altmetric API
raw_metrics <- llply(ids2, altmetrics, .progress = 'text')
metric_data <- ldply(raw_metrics, altmetric_data)
# Sort by Altmetric score
sorted_by_score <- metric_data[with(metric_data, order(score, decreasing=T)), ]
# Filter columns
topscore <- sorted_by_score %>%
select (title,url,score,details_url)
p<-ggplot(data=sorted_by_score, aes(x=readers_count, y=score)) + geom_bar(stat="identity") + geom_text(aes(label=title))
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
p<-ggplot(data=sorted_by_score, aes(x=readers_count, y=score)) + geom_bar(stat="identity") + geom_text(aes(label=title))
ggplot(economics, aes(date, unemploy)) + geom_line()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
p<-ggplot(economics, aes(date, unemploy)) + geom_line()
p
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
ggThemeAssist:::ggThemeAssistAddin()
p<-ggplot(economics, aes(date, unemploy)) + geom_line()
p
ggThemeAssist:::ggThemeAssistAddin()
retrodesign <- function(A, s, alpha=.05, df=Inf, n.sims=10000){
z <- qt(1-alpha/2, df)
p.hi <- 1 - pt(z-A/s, df)
p.lo <- pt(-z-A/s, df)
power <- p.hi + p.lo
typeS <- p.lo/power
estimate <- A + s*rt(n.sims,df)
significant <- abs(estimate) > s*z
exaggeration <- mean(abs(estimate)[significant])/A
return(list(power=power, typeS=typeS, exaggeration=exaggeration))
}
retrodesign(.1, 3.28)
retrodesign(.1, .03)
log(0.90)/1.81
(1.09 - 0.74) / (2*1.96)
((1.09 - 0.74) / (2*1.96)) * ((1.09 - 0.74) / (2*1.96))
0.08928571^2
log(0.90)*(sqrt(3)/3.14)
(log(1.09) - log(0.74)) / (2*1.96)
(log(1.09) - log(0.74)) / (2*1.96) * (sqrt(3)/3.14)
retrodesign(.06,.054)
retrodesign(.05,.05)
library(kableExtra)
setwd("~/Dropbox/-today/replication/workshop/project/manuscripts")
install.packages("stargazer")
choc <- read.dta(../data-clean/choc-data.dta)
library(foreign)
choc <- read.dta(../data-clean/choc-data.dta)
choc <- read.dta("../data-clean/choc-data.dta")
choc <- read.dta("../data-clean/choc-data-clean.dta")
linear.1 <- lm(y ~ treated + as.factor(period), data=choc)
View(choc)
linear.1 <- lm(happy ~ treated + as.factor(period), data=choc)
summary(linear.1)
linear.2 <- lm(happy ~ as.factor(treated) * as.factor(period), data=choc)
summary(linear.2)
install.packages("pander")
install.packages("memisc")
t2
install.packages("texreg")
